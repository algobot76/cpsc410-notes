\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, total={6in, 8in}]{geometry}

\usepackage[normalem]{ulem}

\title{CPSC 410 Notes}
\author{Kaitian Xie}
\date{June 2020}

\begin{document}

\maketitle
\pagebreak

\tableofcontents
\pagebreak

\section{Learning Objectives}

\begin{itemize}
    \item Domain Specific Languages (DSLs)
    \begin{enumerate}
        \item Differentiate Domain Specific Languages (DSLs) from general-purpose programming languages and libraries, and motivate their usefulness.
        \item Design a DSL tailored to assist a target kind of user with specific task.
        \item Implement a DSL simply, providing clear and suitably-robust error handling.
        \item Evaluate a language design's effectiveness via user studies, and incorporate user feedback by processing revisions to a language design.
        \item Compare DSL motivations and justify which you find appropriate (or not).
        \item Judge how useful you find a particular DSL design for a given task/user, identifying and estimating the significance of any weaknesses.
        \item Describe the key stages of a typical DSL implementation, including their roles.
        \item Explain trade-offs regarding whether to have particular phases do more or less work (e.g. fine-grained tokenization, grammar precision, validation).
        \item Propose a suitable tokenization for given input examples in a given language.
        \item Design a corresponding grammar for a given language and tokenization.
        \item Summarise the example tokenization/parsing strategies from the lectures, identifying their advantages and concrete limitations; mention alternatives.
        \item Justify the significance of specific language design principles.
        \item Give examples of considerations that API and designers should be aware of.
        \item Evaluate language features and designs against the language design principles we've discussed in the course, applying your own judgement.
        \item Design and run user studies to evaluate design questions empirically.
        \item Reflect on user feedback to identify potential root causes of any difficulties.
        \item Address these root problems with appropriate redesign ideas.
        \item Implement evaluation methods for an AST (or similar data structures).
        \item Contrast the two evaluation approaches here (AST methods vs. Visitors).
        \item Judge when AST functionality should be refactored using the Visitor Pattern.
        \item Explain how the Visitor pattern simulates double-dispatch, and why double dispatch is important for the user (and reuse) of the pattern.
        \item Choose when to use appropriate extensions of the underlying design patterns.
        \item Give examples of a variety of attributes that may be bound to identifiers.
        \item Differentiate between attributes which are statically and dynamically bound.
        \item Implement language support for standard variable operations.
        \item Select appropriate representations for states used during evaluation.
        \item Illustrate the difference that aliasing makes to observable program behaviours, as well as on the necessary complexity of states used during evaluation.
        \item Contrast the trade-offs between static and dynamic checking, identifying the consequences of each (or neither) for users and language implementers.
        \item Justify whether a correctness property can be checked statically/dynamically.
        \item Implement static and dynamic checkers for particular correctness properties.
        \item Design test cases to illustrate relevant corner cases for a correctness property.
    \end{enumerate}
    \item User-Driven Language Design and Empirical Studies
    \begin{enumerate}
        \item Compare user-centric design (particularly for teaching) with language design in general, giving example motivations for user-centric languages (Logo, Grace) and how their motivations influenced their designs specifically.
        \item Design ethical empirical studies, appropriately identifying risks (and their importance) and strategies for mitigating risks when possible.
        \item Evaluate empirical studies for threats to validity, judge their likely impact on a study's conclusion, and propose strategies for mitigating these when possible.
    \end{enumerate}
    \item Program Analysis and Visualization
    \begin{enumerate}
        \item Differentiate the main types of program analysis, comparing their potential applications, strengths, and weaknesses.
        \item Design program analyses to extract and synthesise information to aid programmers with their daily work.
        \item \sout{Implement simple program analyses and visualizations of their results.}
        \item \sout{Create useful visualizations of programming-related data.}
        \item Justify the likely usefulness of program analyses and visualizations.
        \item Evaluate particular program analyses/visualizations using empirical studies.
        \item Categorise analyses according to the main types presented here, justifying which are necessary/useful for which tasks.
        \item Contrast the pros and cons of raw-data vs. static program analyses, in situations where either could be applicable.
        \item Describe the high-level implementation strategies for making large-scale static/meta-property analyses efficient.
        \item Justify which properties about code a value-agnostic static analysis can be used for (or cannot be used for).
        \item Provide examples of key main points for value-agnostic static analyses.
        \item Define the notion of all-executions properties, giving examples.
        \item Explain the key ideas of the Static Program Slicing technique presented here.
        \item Apply the Static Program Slicing technique to produce program slices for simple imperative programs.
        \item Explain the causes of approximation for static program analyses, giving examples.
        \item Contrast dynamic program analyses with their static counterparts, explaining the typical trade-offs.
        \item Contrast the pros and cons of the main implementation methods for dynamic program analyses (when instrumentation is performed).
        \item Apply the Dynamic Program Slicing technique to produce program slices for simple imperative programs.
        \item Explain the concepts of over- and under-approximation, and their practical consequences for the analysis of correctness properties.
        \item Derive appropriate Failure Conditions for given statements and correctness properties of interest.
        \item Define the key ideas of the symbolic execution techniques presented here, and their meanings in the context of checking correctness properties.
        \item Apply the symbolic execution technique to simple imperative programs.
        \item Justify which of the standard pain points for a program analysis are addressed by symbolic execution (and which are not).
    \end{enumerate}
    \item Digesting and Evaluating PL/SE Research Papers
    \begin{enumerate}
        \item Explain the key things to look for when skim-reading a research paper.
        \item Apply your knowledge of empirical evaluation techniques to critically evaluate the evidence provided in a research paper.
        \item Create short, high-level, summaries of the main points of a research paper.
    \end{enumerate}
\end{itemize}

\section{Domain Specific Languages}

\section{User-Driven Language Design and Empirical Studies}

\section{Program Analysis and Visualization}

\subsection{Main Types of Program Analysis}

\begin{itemize}
    \item Raw Data Analysis
    \begin{itemize}
        \item Analysis of raw data, not structured program representation (e.g. ASTs).
        \item Strengths
        \begin{itemize}
            \item Quick and easy.
            \item Can be built on a pre-exiting raw data analysis.
        \end{itemize}
        \item Weaknesses
        \begin{itemize}
            \item Not precise/detailed.
        \end{itemize}
        \item Applications
        \begin{itemize}
            \item diff
            \item grep, sed
            \item git (e.g. git blame)
            \item Issue tracker info (e.g. GitHub)
        \end{itemize}
    \end{itemize}
    \item Meta-Properties Analysis
    \begin{itemize}
        \item Analysis of project-level/software process metrics.
        \item Applications
        \begin{itemize}
            \item Show git history.
        \end{itemize}
    \end{itemize}
    \item Static Program Analysis
    \begin{itemize}
        \item Analysis of structured source code (ASTs) before running it.
        \item Applications
        \begin{itemize}
            \item Enforcing coding guidelines (value-agnostic).
            \item Reporting potential behaviours (value-sensitive).
        \end{itemize}
    \end{itemize}
    \item Dynamic Program Analysis
    \begin{itemize}
        \item Analysis of code while running it.
        \item Applications
        \begin{itemize}
            \item Runtime checks (e.g. array bounds).
            \item Debugger.
        \end{itemize}
    \end{itemize}
\end{itemize}

\section{Digesting and Evaluating PL/SE Research Papers}

\end{document}
